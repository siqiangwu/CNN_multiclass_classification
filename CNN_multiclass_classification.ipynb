{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV4osAJhnrTv",
        "colab_type": "text"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gqh8kPlgiFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adadelta, Adam, SGD\n",
        "from keras.layers import Input, Conv2D, Dense, MaxPooling2D, Dropout, Flatten, AveragePooling2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.models import Sequential\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks\") # might have to change path to point to your Colab Notebooks folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eJJXcB1n2kn",
        "colab_type": "text"
      },
      "source": [
        "## Load and format data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgjqOlNDE3tJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.load('./MNIST_CorrNoise.npz')\n",
        "\n",
        "x_train = data['x_train']\n",
        "y_train = data['y_train']\n",
        "\n",
        "num_cls = len(np.unique(y_train))\n",
        "print('Number of classes: ' + str(num_cls))\n",
        "\n",
        "print('Example of handwritten digit with correlated noise: \\n')\n",
        "\n",
        "k = 3000\n",
        "plt.imshow(np.squeeze(x_train[k,:,:]))\n",
        "plt.show()\n",
        "print('Class: '+str(y_train[k])+'\\n')\n",
        "\n",
        "# RESHAPE and standarize\n",
        "x_train = np.expand_dims(x_train/255,axis=3)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_cls)\n",
        "\n",
        "print('Shape of x_train: '+str(x_train.shape))\n",
        "print('Shape of y_train: '+str(y_train.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFPhNWgloVIh",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAE8wRG_pypQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name='CNN' # To compare models, you can give them different names\n",
        "\n",
        "pweight='./weights/weights_' + model_name  + '.hdf5'\n",
        "\n",
        "if not os.path.exists('./weights'):\n",
        "  os.mkdir('./weights')\n",
        "\n",
        "## EXPLORE VALUES AND FIND A GOOD SET\n",
        "b_size = ? # batch size\n",
        "val_split = ? # percentage of samples used for validation (e.g. 0.5)\n",
        "ep = ? # number of epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Ii3Irf3F0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = x_train.shape[1:4] #(28,28,1)\n",
        "model = Sequential()\n",
        "\n",
        "## EXPLORE LAYERS, # CHANNELS... Conv2D, Dense, MaxPooling2D, Dropout, Flatten, AveragePooling2D, Conv2DTranspose, UpSampling2D\n",
        "## SEE KERAS MANUAL https://keras.io/layers/about-keras-layers/\n",
        "model.add(Conv2D(1, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) # explore num channels and adding more layers\n",
        "model.add(Flatten()) # transforms matrix feature map to vector for dense layer (fully connected)\n",
        "##\n",
        "model.add(Dense(num_cls, activation='softmax')) # This is a necessary output layer, however, you can add more dense layers before with different activation functions\n",
        "\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adadelta(), # explore other optimizers: Adam, SGD\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=pweight, verbose=1, save_best_only=True)\n",
        "callbacks_list = [checkpointer] # explore adding other callbacks such as ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "history=model.fit(x_train, y_train,\n",
        "                        epochs=ep,\n",
        "                        batch_size=b_size,\n",
        "                        verbose=1,\n",
        "                        shuffle=True,\n",
        "                        validation_split = val_split,\n",
        "                        callbacks=callbacks_list)\n",
        "\n",
        "print('CNN weights saved in ' + pweight)\n",
        "\n",
        "# Plot loss vs epochs\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy vs epochs\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3dbqKloipP",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions in test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPLSp4PppXE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "## LOAD DATA\n",
        "data = np.load('./MNIST_CorrNoise.npz')\n",
        "\n",
        "x_test = data['x_test']\n",
        "y_test = data['y_test']\n",
        "\n",
        "num_cls = len(np.unique(y_test))\n",
        "print('Number of classes: ' + str(num_cls))\n",
        "\n",
        "# RESHAPE and standarize\n",
        "x_test = np.expand_dims(x_test/255,axis=3)\n",
        "\n",
        "print('Shape of x_train: '+str(x_test.shape)+'\\n')\n",
        "\n",
        "## Define model parameters\n",
        "model_name='CNN' # To compare models, you can give them different names\n",
        "pweight='./weights/weights_' + model_name  + '.hdf5'\n",
        "\n",
        "model = load_model(pweight)\n",
        "y_pred = model.predict_classes(x_test)\n",
        "\n",
        "Acc_pred = sum(y_pred == y_test)/len(y_test)\n",
        "\n",
        "print('Accuracy in test set is: '+str(Acc_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}